{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f56a51",
   "metadata": {},
   "source": [
    "# Preprocess The Images\n",
    "Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\n",
    "\n",
    "The Keras deep learning neural network library provides the capability to fit models using image data augmentation via the ImageDataGenerator class.\n",
    "\n",
    "The first step is usually importing the libraries that will be needed in the program.\n",
    "Import Keras library from that library import the ImageDataGenerator Library to your Python script:\n",
    "After each code block in this tutorial, you should type ALT + ENTER or SHIFT+ENTER to run the code and move into a new code block within your notebook.\n",
    "\n",
    "Let us import the ImageDataGenerator class from Keras\n",
    "Import ImageDataGenerator Library and Configure it\n",
    "ImageDataGenerator class is used to load the images with different modifications like considering the zoomed image, flipping the image and rescaling the images to range of 0 and 1.\n",
    "\n",
    "\n",
    "# There are five main types of data augmentation techniques for image data; specifically:\n",
    "\n",
    "Image shifts via the width_shift_range and height_shift_range arguments.\n",
    "The image flips via the horizontal_flip and vertical_flip arguments.\n",
    "The image rotates  via the rotation_range argument\n",
    "Image brightness via the brightness_range argument.\n",
    "The image zooms via the zoom_range argument.\n",
    "An instance of the ImageDataGenerator class can be constructed for train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48131ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Tensorflow in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (2.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (1.47.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (1.23.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (3.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (3.19.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (0.26.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (61.2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (4.1.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from Tensorflow) (14.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from astunparse>=1.6.0->Tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from tensorboard<2.9,>=2.8->Tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from tensorboard<2.9,>=2.8->Tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from tensorboard<2.9,>=2.8->Tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from tensorboard<2.9,>=2.8->Tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from tensorboard<2.9,>=2.8->Tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from tensorboard<2.9,>=2.8->Tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from tensorboard<2.9,>=2.8->Tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->Tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->Tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->Tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->Tensorflow) (3.2.0)\n",
      "Requirement already satisfied: keras in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\dell\\anaconda3\\envs\\keras_env\\lib\\site-packages (9.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Tensorflow\n",
    "!pip install keras\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9ac6d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f9455",
   "metadata": {},
   "source": [
    "# Apply ImageDataGenerator functionality to Train and Test set\n",
    "Specify the path of both the folders in the flow_from_directory method. We are importing the images in 128*128 pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78cedcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5384 images belonging to 6 classes.\n",
      "Found 1686 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory('C:/Users/Dell/Desktop/Dataset Plant Disease/fruit-dataset/fruit-dataset/train', target_size=(128,128),batch_size=32,class_mode='categorical')\n",
    "x_test=test_datagen.flow_from_directory('C:/Users/Dell/Desktop/Dataset Plant Disease/fruit-dataset/fruit-dataset/test', target_size=(128,128),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41f29345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple___Black_rot': 0,\n",
       " 'Apple___healthy': 1,\n",
       " 'Corn_(maize)___Northern_Leaf_Blight': 2,\n",
       " 'Corn_(maize)___healthy': 3,\n",
       " 'Peach___Bacterial_spot': 4,\n",
       " 'Peach___healthy': 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16c000",
   "metadata": {},
   "source": [
    "# Model Building For Fruit Disease Prediction\n",
    "We are ready with the augmented and pre-processed image data, Lets begin our model building, this activity includes the following steps\n",
    "//Import the model building Libraries\n",
    "//Initializing the model\n",
    "Adding CNN Layers\n",
    "Adding Hidden Layer\n",
    "Adding Output Layer\n",
    "Configure the Learning Process\n",
    "Training and testing the model\n",
    "Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83173352",
   "metadata": {},
   "source": [
    "# Import The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15188a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7ea8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d1118",
   "metadata": {},
   "source": [
    "# Initializing The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb79c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a6f5c",
   "metadata": {},
   "source": [
    "# ADD CNNLayers\n",
    "We will be adding three layers for CNN\n",
    "Convolution layer\n",
    "Pooling layer\n",
    "Flattening layer\n",
    "Add Convolution Layer\n",
    "\n",
    "The first layer of the neural network model, the convolution layer will be added. To create a convolution layer, Convolution2D class is used. It takes a number of feature detectors, feature detector size, expected input shape of the image, and activation function as arguments. This layer applies feature detectors on the input image and returns a feature map (features from the image).\n",
    "\n",
    "Activation Function: These are the functions that help us to decide if we need to activate the node or not. These functions introduce non-linearity in the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa29c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(4,4), input_shape=(128,128,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d94e56",
   "metadata": {},
   "source": [
    "# Add the pooling layer\n",
    "Max Pooling selects the maximum element from the region of the feature map covered by the filter. Thus, the output after the max-pooling layer would be a feature map containing the most prominent features of the previous feature map.\n",
    "\n",
    "After the convolution layer, a pooling layer is added. Max pooling layer can be added using MaxPooling2D class. It takes the pool size as a parameter. Efficient size of the pooling matrix is (2,2). It returns the pooled feature maps. (Note: Any number of convolution layers, pooling and dropout layers can be added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80705b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c465f",
   "metadata": {},
   "source": [
    "# The flatten layer is used to convert n-dimensional arrays to 1-dimensional arrays. This 1D array will be given as input to ANN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ebee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d4d97",
   "metadata": {},
   "source": [
    "# Add Dense Layers\n",
    "Now, let's add Dense Layers to know more about dense layers click below\n",
    "\n",
    "Denselayers \n",
    "\n",
    "The name suggests that layers are fully connected (dense) by the neurons in a network layer. Each neuron in a layer receives input from all the neurons present in the previous layer. Dense is used to add the layers.\n",
    "\n",
    "Adding Hidden layers\n",
    "\n",
    "This step is to add a dense layer (hidden layer). We flatten the feature map and convert it into a vector or single dimensional array in the Flatten layer. This vector array is fed it as an input to the neural network and applies an activation function, such as sigmoid or other, and returns the output.\n",
    "init is the weight initialization; function which sets all the weights and biases of a network to values suitable as a starting point for training.\n",
    "units/ output_dim, which denote is the number of neurons in the hidden layer. \n",
    "The activation function basically decides to deactivate neurons or activate them to get the desired output. It also performs a nonlinear transformation on the input to get better results on a complex neural network. \n",
    "You can add many hidden layers, in our project we are added two hidden layers. The 1st hidden layer with 40 neurons and 2nd hidden layer with 20neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae02883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(40, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(20, kernel_initializer='random_uniform', activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461c358",
   "metadata": {},
   "source": [
    "# Adding the output layer\n",
    "\n",
    "This step is to add a dense layer (output layer) where you will be specifying the number of classes your dependent variable has, activation function, and weight initializer as the arguments. We use the add () method to add dense layers. the output dimensions here is 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc346fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(6, kernel_initializer='random_uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d7358",
   "metadata": {},
   "source": [
    "# Train And Save The Model\n",
    "\n",
    " # Compile the model\n",
    " \n",
    "After adding all the required layers, the model is to be compiled. For this step, loss function, optimizer and metrics for evaluation can be passed as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90276bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e29852",
   "metadata": {},
   "source": [
    "# Fit and save the model\n",
    "\n",
    "Fit the neural network model with the train and test set, number of epochs and validation steps. Steps per epoch is determined by number of training images//batch size, for validation steps number of validation images//batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dda1da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v2.version' from 'C:\\\\Users\\\\Dell\\\\anaconda3\\\\envs\\\\keras_env\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\version\\\\__init__.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ac8f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "169/169 [==============================] - 196s 1s/step - loss: 0.7823 - accuracy: 0.7121 - val_loss: 118.2506 - val_accuracy: 0.6429\n",
      "Epoch 2/10\n",
      "169/169 [==============================] - 154s 915ms/step - loss: 0.4800 - accuracy: 0.8280 - val_loss: 146.6210 - val_accuracy: 0.7331\n",
      "Epoch 3/10\n",
      "169/169 [==============================] - 167s 990ms/step - loss: 0.3482 - accuracy: 0.8800 - val_loss: 229.2009 - val_accuracy: 0.6803\n",
      "Epoch 4/10\n",
      "169/169 [==============================] - 145s 856ms/step - loss: 0.2888 - accuracy: 0.9021 - val_loss: 181.9814 - val_accuracy: 0.7800\n",
      "Epoch 5/10\n",
      "169/169 [==============================] - 125s 742ms/step - loss: 0.2576 - accuracy: 0.9088 - val_loss: 278.5514 - val_accuracy: 0.7325\n",
      "Epoch 6/10\n",
      "169/169 [==============================] - 74s 439ms/step - loss: 0.2375 - accuracy: 0.9149 - val_loss: 305.3044 - val_accuracy: 0.7295\n",
      "Epoch 7/10\n",
      "169/169 [==============================] - 74s 439ms/step - loss: 0.2103 - accuracy: 0.9290 - val_loss: 240.8337 - val_accuracy: 0.7414\n",
      "Epoch 8/10\n",
      "169/169 [==============================] - 73s 434ms/step - loss: 0.1981 - accuracy: 0.9283 - val_loss: 326.9644 - val_accuracy: 0.6720\n",
      "Epoch 9/10\n",
      "169/169 [==============================] - 74s 436ms/step - loss: 0.1896 - accuracy: 0.9333 - val_loss: 412.0005 - val_accuracy: 0.6257\n",
      "Epoch 10/10\n",
      "169/169 [==============================] - 74s 438ms/step - loss: 0.1848 - accuracy: 0.9318 - val_loss: 716.3803 - val_accuracy: 0.6346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fba2f38970>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, steps_per_epoch=len(x_train), validation_data=x_test,validation_steps=len(x_test), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c83ecd",
   "metadata": {},
   "source": [
    "Accuracy, Loss: Loss value implies how poorly or well a model behaves after each iteration of optimization. An accuracy metric is used to measure the algorithm's performance in an interpretable way. The accuracy of a model is usually determined after the model parameters and is calculated in the form of a percentage.\n",
    "\n",
    "The weights are to be saved for future use. The weights are saved in as .h5 file using save()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3f22a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fruit.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c9a1df",
   "metadata": {},
   "source": [
    "model.summary() can be used to see all parameters and shapes in each layer in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd004542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 125, 125, 32)      1568      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 62, 62, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 123008)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 40)                4920360   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 126       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,922,874\n",
      "Trainable params: 4,922,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7e4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
